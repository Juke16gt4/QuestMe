//
//  SpeechInputView.swift
//  QuestMe
//
//  ğŸ“‚ æ ¼ç´å ´æ‰€:
//      QuestMe/Views/Medication/SpeechInputView.swift
//
//  ğŸ¯ ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„:
//      ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€Speech Framework ã§æ–‡å­—èµ·ã“ã—ã™ã‚‹ãƒ“ãƒ¥ãƒ¼ã€‚
//      - è–¬å‰¤åã¨å®¹é‡ã‚’æŠ½å‡ºã—ã¦ Medication.sqlite3 ã«ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚
//      - éŸ³å£°èªè­˜ä¸­ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—åˆ—ã‚’æ›´æ–°ã€‚
//      - ä¿å­˜æ™‚ã« completion ã§çµæœã‚’è¿”ã™ã€‚
//
//  ğŸ”— ä¾å­˜:
//      - Speechï¼ˆéŸ³å£°èªè­˜ï¼‰
//      - MedicationDialog.swiftï¼ˆå‘¼ã³å‡ºã—å…ƒï¼‰
//      - MedicationManager.swiftï¼ˆä¿å­˜ï¼‰
//
//  ğŸ‘¤ è£½ä½œè€…: æ´¥æ‘ æ·³ä¸€
//  ğŸ“… åˆ¶ä½œæ—¥: 2025å¹´10æœˆ4æ—¥

import SwiftUI
import Speech

struct SpeechInputView: View {
    @Environment(\.dismiss) private var dismiss
    @State private var recognizedText = "è©±ã—ã¦ãã ã•ã„â€¦"
    @State private var isRecording = false

    var completion: (Result<String, Error>) -> Void

    private let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP"))
    private let audioEngine = AVAudioEngine()
    private var request = SFSpeechAudioBufferRecognitionRequest()
    private var recognitionTask: SFSpeechRecognitionTask?

    var body: some View {
        VStack(spacing: 20) {
            Text("éŸ³å£°å…¥åŠ›")
                .font(.headline)

            Text(recognizedText)
                .padding()
                .frame(maxWidth: .infinity)
                .background(Color.gray.opacity(0.1))
                .clipShape(RoundedRectangle(cornerRadius: 8))

            Button(isRecording ? "åœæ­¢" : "éŒ²éŸ³é–‹å§‹") {
                if isRecording {
                    stopRecording()
                } else {
                    startRecording()
                }
            }
            .padding()
            .background(Color.blue.opacity(0.8))
            .foregroundColor(.white)
            .clipShape(Capsule())

            Button("ä¿å­˜") {
                completion(.success(recognizedText))
                dismiss()
            }
        }
        .padding()
        .onDisappear {
            stopRecording()
        }
    }

    private func startRecording() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            guard authStatus == .authorized else {
                completion(.failure(NSError(domain: "SpeechAuth", code: -1)))
                return
            }

            do {
                let node = audioEngine.inputNode
                let recordingFormat = node.outputFormat(forBus: 0)
                node.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
                    self.request.append(buffer)
                }

                audioEngine.prepare()
                try audioEngine.start()

                recognitionTask = recognizer?.recognitionTask(with: request) { result, error in
                    if let result = result {
                        DispatchQueue.main.async {
                            self.recognizedText = result.bestTranscription.formattedString
                        }
                    } else if let error = error {
                        self.completion(.failure(error))
                    }
                }

                DispatchQueue.main.async {
                    self.isRecording = true
                }
            } catch {
                completion(.failure(error))
            }
        }
    }

    private func stopRecording() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        request.endAudio()
        recognitionTask?.cancel()
        DispatchQueue.main.async {
            self.isRecording = false
        }
    }
}
