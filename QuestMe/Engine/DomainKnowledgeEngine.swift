//
//  DomainKnowledgeEngine.swift
//  QuestMe
//
//  ğŸ“‚ æ ¼ç´å ´æ‰€:
//      QuestMe/Engine/DomainKnowledgeEngine.swift
//
//  ğŸ¯ ç›®çš„:
//      å…¨åˆ†é‡ã®çŸ¥è­˜ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆå¿ƒè‡“éƒ¨ï¼‰ã€‚
//      - ConversationSubject ã‚’åˆ©ç”¨ã—ã¦è©±é¡Œã‚’ç®¡ç†
//      - å„ NewsService ã‚’å‘¼ã³å‡ºã—ã¦è¨˜äº‹ã‚’å–å¾—
//      - ç™ºè©±ã¨ Core Data ãƒ­ã‚°ä¿å­˜ã‚’çµ±åˆ
//
//  ğŸ”— ä¾å­˜:
//      - ConversationSubject.swift
//      - EmotionType.swift
//      - EmotionLogRepository.swift
//      - AVFoundation
//      - å„åˆ†é‡ã® Models / NewsService ç¾¤
//
//  ğŸ‘¤ è£½ä½œè€…: æ´¥æ‘ æ·³ä¸€
//  ğŸ“… æ”¹å¤‰æ—¥: 2025å¹´10æœˆ15æ—¥
//

import Foundation
import Combine
import AVFoundation

final class DomainKnowledgeEngine: ObservableObject {
    @Published var currentSubject: ConversationSubject = ConversationSubject(label: "æœªè¨­å®š")
    @Published var classification: String = ""
    @Published var articles: [String] = []

    private let synthesizer = AVSpeechSynthesizer()

    // âœ… æ–¹æ³•â‘ é©ç”¨ï¼šprivate â†’ internal ã«å¤‰æ›´
    /// æ–‡å­¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆå¤–éƒ¨ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ï¼‰
    let literatureNews = LiteratureNewsService()

    // åˆ†é¡
    func classify(_ subject: ConversationSubject) {
        let t = subject.label
        switch true {
        case t.contains("æ–‡å­¦"), t.contains("å°èª¬"), t.contains("è©©"), t.contains("ä½œå®¶"):
            classification = "ç¾ä»£æ–‡å­¦"
        default:
            classification = "ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹"
        }
    }

    // ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    func fetchNews(for subject: ConversationSubject) async {
        classify(subject)
        switch classification {
        case "ç¾ä»£æ–‡å­¦":
            let items = await literatureNews.fetchLatest(for: .novel)
            articles = items.map { $0.title }
        default:
            articles = ["ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ€ãƒŸãƒ¼è¨˜äº‹"]
        }
    }

    // ç™ºè©±ï¼‹ãƒ­ã‚°ä¿å­˜
    func speakAndLog(text: String,
                     emotion: EmotionType,
                     ritual: String,
                     metadata: [String: Any] = [:]) {
        let u = AVSpeechUtterance(string: text)
        u.voice = AVSpeechSynthesisVoice(language: "ja-JP")
        u.rate = 0.5
        synthesizer.speak(u)

        EmotionLogRepository.shared.saveLog(
            text: text,
            emotion: emotion,
            ritual: ritual,
            metadata: metadata
        )
    }
}
