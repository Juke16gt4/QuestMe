//
//  ExpertiseDomainsView.swift
//  QuestMe
//
//  ğŸ“‚ æ ¼ç´å ´æ‰€:
//      QuestMe/UI/ExpertiseDomainsView.swift
//
//  ğŸ¯ ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„:
//      QuestMeãŒå¯¾å¿œã™ã‚‹å°‚é–€åˆ†é‡ã‚’è¡¨å½¢å¼ã§æç¤ºã—ã€éŸ³å£°ã§å®‰å¿ƒæ„Ÿã‚’å±Šã‘ã‚‹ã€‚
//      - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã©ã‚“ãªåˆ†é‡ã«è©±ã—ã‹ã‘ã‚‰ã‚Œã‚‹ã‹ã€ã‚’è¦–è¦šã¨è´è¦šã§ç†è§£ã€‚
//      - æ„Ÿæƒ…åŒæœŸã¨çŸ¥çš„ä¿¡é ¼ã‚’ä¸¡ç«‹ã€‚
//      ä¾å­˜æ¶ˆå¤±ï¼ˆCompanionOverlay / SpeechServiceï¼‰ã«ä¼´ã„ã€ç™ºè©±æ©Ÿèƒ½ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«å†…è”µã€‚
//
//  ğŸ”— ä¾å­˜:
//      - SwiftUI
//      - EmotionType.swiftï¼ˆæ„Ÿæƒ…å®šç¾©ï¼‰
//
//  ğŸ‘¤ è£½ä½œè€…: æ´¥æ‘ æ·³ä¸€
//  ğŸ“… æ”¹åæ—¥: 2025å¹´10æœˆ14æ—¥
//

import SwiftUI
import AVFoundation

struct ExpertiseDomainsView: View {
    // å¿…è¦ã«å¿œã˜ã¦å¹ãå‡ºã—ã‚’å‡ºã™å ´åˆã®çŠ¶æ…‹ï¼ˆä»Šå›ã¯ç”»é¢å†…ç™ºè©±ã®ã¿ï¼‰
    @State private var showSpeechBubble = false
    @State private var currentEmotion: EmotionType = .gentle
    @State private var currentSpeechText: String = ""

    private let synthesizer = AVSpeechSynthesizer()

    var body: some View {
        VStack(spacing: 20) {
            if showSpeechBubble {
                CompanionSpeechBubbleView(text: currentSpeechText, emotion: currentEmotion)
                    .padding(.horizontal, 16)
            }

            Text("ğŸ§  QuestMeãŒå¯¾å¿œã™ã‚‹å°‚é–€åˆ†é‡")
                .font(.title2)
                .bold()

            Grid(alignment: .leading, horizontalSpacing: 24, verticalSpacing: 12) {
                GridRow {
                    Text("åŒ»ç™‚ãƒ»è–¬å­¦")
                    Text("æ³•å¾‹ãƒ»åˆ¶åº¦")
                    Text("ITãƒ»æŠ€è¡“")
                }
                GridRow {
                    Text("é‡‘èãƒ»çµŒæ¸ˆ")
                    Text("èªå­¦ãƒ»å›½éš›")
                    Text("ãƒ“ã‚¸ãƒã‚¹ãƒ»ç®¡ç†")
                }
                GridRow {
                    Text("è‡ªç„¶ç§‘å­¦")
                    Text("å¿ƒç†ãƒ»ç¦ç¥‰")
                    Text("æ­´å²ãƒ»å“²å­¦")
                }
                GridRow {
                    Text("èŠ¸è¡“ãƒ»éŸ³æ¥½")
                    Text("å·¥å­¦ãƒ»è¨­è¨ˆ")
                    Text("æ•™è‚²ãƒ»è³‡æ ¼")
                }
            }
            .font(.body)
            .padding()

            Spacer()
        }
        .padding()
        .onAppear {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                speak("ã“ã‚Œã‚‰ã®åˆ†é‡ã¯ã™ã¹ã¦éŸ³å£°ã§ã‚‚å¯¾å¿œã§ãã¾ã™ã‚ˆã€‚è³ªå•ã—ã¦ã¿ã¦ãã ã•ã„ã€‚", emotion: .gentle)
            }
        }
    }

    private func speak(_ text: String, emotion: EmotionType) {
        // æ„Ÿæƒ…ã¨å¹ãå‡ºã—ï¼ˆå¿…è¦ãªã‚‰è¡¨ç¤ºï¼‰
        currentEmotion = emotion
        currentSpeechText = text
        showSpeechBubble = true

        // éŸ³å£°åˆæˆï¼ˆja-JPï¼‰
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "ja-JP")
        utterance.rate = 0.5
        synthesizer.speak(utterance)

        DispatchQueue.main.asyncAfter(deadline: .now() + 4.0) {
            showSpeechBubble = false
        }
    }
}
